{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prune characters effectively using the three metrics (**in-mentions**, **word count**, and **out-mentions**), we can adopt ranking strategies that prioritize **in-mentions** and **word count** while still accounting for **out-mentions**. Below are some approaches to solve this:\n",
    "\n",
    "---\n",
    "\n",
    "### **Option 1: Weighted Scoring**\n",
    "Assign weights to each metric based on its importance. Compute a total score for each character, and filter characters based on their scores:\n",
    "1. **Define Weights**:\n",
    "   - Assign higher weights to **in-mentions** and **word count** compared to **out-mentions**.\n",
    "   - Example: `in-mentions = 0.4`, `word count = 0.4`, `out-mentions = 0.2`.\n",
    "2. **Score Formula**:\n",
    "   ```python\n",
    "   score = 0.4 * normalized_in_mentions + 0.4 * normalized_word_count + 0.2 * normalized_out_mentions\n",
    "   ```\n",
    "   Normalize the values to a range of `[0, 1]` using min-max scaling:\n",
    "   ```python\n",
    "   normalized_value = (value - min_value) / (max_value - min_value)\n",
    "   ```\n",
    "3. **Sort and Filter**:\n",
    "   - Rank characters by their scores and prune based on a threshold or keep the top N characters.\n",
    "\n",
    "---\n",
    "\n",
    "### **Option 2: Multi-Metric Ranking**\n",
    "Rank characters separately by each metric and combine their rankings to create a composite rank:\n",
    "1. **Rank by Each Metric**:\n",
    "   - Create three sorted lists: \n",
    "     - By **in-mentions** (descending).\n",
    "     - By **word count** (descending).\n",
    "     - By **out-mentions** (descending).\n",
    "   - Assign a rank to each character for each metric.\n",
    "2. **Weighted Rank Sum**:\n",
    "   - Compute a combined rank for each character using weights (e.g., `in-mentions_rank * 0.4 + word_count_rank * 0.4 + out_mentions_rank * 0.2`).\n",
    "3. **Filter**:\n",
    "   - Keep characters with the lowest combined ranks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Option 3: Pareto Optimal Filtering**\n",
    "Use a **Pareto frontier approach** to retain characters that are optimal with respect to the three metrics:\n",
    "1. **Pareto Principle**:\n",
    "   - A character is considered \"better\" if no other character outperforms it in all three metrics.\n",
    "2. **Filter with Thresholds**:\n",
    "   - Define a threshold for each metric (e.g., `in-mentions > 3`, `word count > 50`) and retain only characters satisfying these thresholds.\n",
    "\n",
    "---\n",
    "\n",
    "### **Option 4: Custom Rule-Based Filtering**\n",
    "Define a set of rules to prune characters explicitly based on your priorities:\n",
    "1. **Rules**:\n",
    "   - Retain characters with **in-mentions > X** or **word count > Y** regardless of their out-mentions.\n",
    "   - Optionally, remove characters with **out-mentions < Z**.\n",
    "2. **Implementation**:\n",
    "   - Iterate through the dictionary, applying the rules and removing characters that fail.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Choose?**\n",
    "- **Weighted Scoring**: Flexible and provides a continuous score. Good if you want to rank characters and pick the top ones.\n",
    "- **Multi-Metric Ranking**: Provides transparency in how rankings are combined. Better if you want to understand relative importance.\n",
    "- **Pareto Filtering**: Useful for retaining the \"best\" characters without predefined thresholds. May require manual inspection of results.\n",
    "- **Rule-Based Filtering**: Simple and fast if you know specific thresholds for pruning.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Code: Weighted Scoring\n",
    "\n",
    "```python\n",
    "def prune_characters(char_summary, weights={\"in\": 0.4, \"words\": 0.4, \"out\": 0.2}, keep_top=10):\n",
    "    # Extract metrics\n",
    "    in_counts = [len(data[\"mentioned_by\"]) for data in char_summary.values()]\n",
    "    word_counts = [data[\"word_count\"] for data in char_summary.values()]\n",
    "    out_counts = [len(data[\"mentions\"]) for data in char_summary.values()]\n",
    "    \n",
    "    # Normalize metrics\n",
    "    def normalize(data):\n",
    "        min_val, max_val = min(data), max(data)\n",
    "        return [(x - min_val) / (max_val - min_val) if max_val > min_val else 0 for x in data]\n",
    "    \n",
    "    norm_in_counts = normalize(in_counts)\n",
    "    norm_word_counts = normalize(word_counts)\n",
    "    norm_out_counts = normalize(out_counts)\n",
    "    \n",
    "    # Compute weighted scores\n",
    "    scores = {}\n",
    "    for idx, char in enumerate(char_summary):\n",
    "        scores[char] = (\n",
    "            weights[\"in\"] * norm_in_counts[idx] +\n",
    "            weights[\"words\"] * norm_word_counts[idx] +\n",
    "            weights[\"out\"] * norm_out_counts[idx]\n",
    "        )\n",
    "    \n",
    "    # Sort characters by scores\n",
    "    sorted_characters = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Keep top N characters\n",
    "    pruned_summary = {char: char_summary[char] for char, score in sorted_characters[:keep_top]}\n",
    "    return pruned_summary\n",
    "```\n",
    "\n",
    "### Example Code: Multi-Metric Ranking\n",
    "\n",
    "```python\n",
    "def prune_characters_by_rank(char_summary, weights={\"in\": 0.4, \"words\": 0.4, \"out\": 0.2}, keep_top=10):\n",
    "    # Extract metrics\n",
    "    in_counts = {char: len(data[\"mentioned_by\"]) for char, data in char_summary.items()}\n",
    "    word_counts = {char: data[\"word_count\"] for char, data in char_summary.items()}\n",
    "    out_counts = {char: len(data[\"mentions\"]) for char, data in char_summary.items()}\n",
    "    \n",
    "    # Rank characters by each metric\n",
    "    def rank(data):\n",
    "        return {k: rank for rank, (k, v) in enumerate(sorted(data.items(), key=lambda x: x[1], reverse=True), 1)}\n",
    "    \n",
    "    in_ranks = rank(in_counts)\n",
    "    word_ranks = rank(word_counts)\n",
    "    out_ranks = rank(out_counts)\n",
    "    \n",
    "    # Compute weighted rank sum\n",
    "    scores = {\n",
    "        char: (\n",
    "            weights[\"in\"] * in_ranks[char] +\n",
    "            weights[\"words\"] * word_ranks[char] +\n",
    "            weights[\"out\"] * out_ranks[char]\n",
    "        )\n",
    "        for char in char_summary\n",
    "    }\n",
    "    \n",
    "    # Sort characters by scores\n",
    "    sorted_characters = sorted(scores.items(), key=lambda x: x[1])\n",
    "    \n",
    "    # Keep top N characters\n",
    "    pruned_summary = {char: char_summary[char] for char, score in sorted_characters[:keep_top]}\n",
    "    return pruned_summary\n",
    "\n",
    "def pareto_filter(char_summary):\n",
    "    # Extract metrics\n",
    "    metrics = [\n",
    "        (char, len(data[\"mentioned_by\"]), data[\"word_count\"], len(data[\"mentions\"]))\n",
    "        for char, data in char_summary.items()\n",
    "    ]\n",
    "    \n",
    "    # Pareto frontier computation\n",
    "    pareto_frontier = []\n",
    "    for char, in_count, word_count, out_count in metrics:\n",
    "        if not any(\n",
    "            other_in > in_count and other_words > word_count and other_out > out_count\n",
    "            for _, other_in, other_words, other_out in metrics\n",
    "        ):\n",
    "            pareto_frontier.append(char)\n",
    "    \n",
    "    # Return filtered dictionary\n",
    "    return {char: char_summary[char] for char in pareto_frontier}\n",
    "\n",
    "\n",
    "def percentile_filter(char_summary, percentile=90):\n",
    "    # Extract metrics\n",
    "    in_counts = [len(data[\"mentioned_by\"]) for data in char_summary.values()]\n",
    "    word_counts = [data[\"word_count\"] for data in char_summary.values()]\n",
    "    out_counts = [len(data[\"mentions\"]) for data in char_summary.values()]\n",
    "    \n",
    "    # Compute percentile thresholds\n",
    "    in_threshold = np.percentile(in_counts, percentile)\n",
    "    word_threshold = np.percentile(word_counts, percentile)\n",
    "    out_threshold = np.percentile(out_counts, percentile)\n",
    "    \n",
    "    # Filter characters\n",
    "    filtered_summary = {\n",
    "        char: data for char, data in char_summary.items()\n",
    "        if len(data[\"mentioned_by\"]) >= in_threshold\n",
    "        or data[\"word_count\"] >= word_threshold\n",
    "        or len(data[\"mentions\"]) >= out_threshold\n",
    "    }\n",
    "    \n",
    "    return filtered_summary\n",
    "```\n",
    "---\n",
    "\n",
    "### Key Notes\n",
    "1. **Pareto Filtering**:\n",
    "   - Retains characters that cannot be strictly outperformed on all metrics by others.\n",
    "   - Tends to keep a diverse set of \"strong\" characters.\n",
    "\n",
    "2. **Percentile-Based Filtering**:\n",
    "   - Removes characters that fall below the 90th percentile in **all** metrics.\n",
    "   - Adjustable by changing the `percentile` parameter (e.g., to 85% or 95%).\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
